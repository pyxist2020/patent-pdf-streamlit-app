import streamlit as st
import json
import os
import tempfile
import time
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd

# æ–°ã—ã„ä¸¦åˆ—å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from patent_extractor import PatentExtractor
    EXTRACTOR_AVAILABLE = True
except ImportError:
    EXTRACTOR_AVAILABLE = False
    st.error("âŒ æŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚patent_extractor.py ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸš€ ä¸¦åˆ—ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .metric-row {
        display: flex;
        gap: 20px;
        margin: 20px 0;
    }
    .metric-card {
        flex: 1;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        border: 1px solid #e0e0e0;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .performance-info {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin: 15px 0;
    }
    .domain-badge {
        display: inline-block;
        padding: 5px 15px;
        border-radius: 20px;
        background: #4CAF50;
        color: white;
        font-weight: bold;
        margin: 5px;
    }
    .stProgress .st-bo {
        background-color: #667eea;
    }
    .success-metrics {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
    }
    .error-metrics {
        background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%);
        color: white;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
DEFAULT_MODEL_OPTIONS = {
    "Google Gemini": ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"],
    "OpenAI": ["gpt-4o", "gpt-4-vision-preview", "gpt-4-turbo", "gpt-3.5-turbo"],
    "Anthropic": ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
}

def get_api_key_from_env(provider):
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—"""
    env_vars = {
        "Google Gemini": "GOOGLE_API_KEY",
        "OpenAI": "OPENAI_API_KEY", 
        "Anthropic": "ANTHROPIC_API_KEY"
    }
    return os.environ.get(env_vars.get(provider, ""), "")

@st.cache_data(ttl=3600)
def fetch_available_models(provider, api_key):
    """APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    try:
        if not api_key:
            return []
        
        if provider == "Google Gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models = genai.list_models()
            return [model.name.replace('models/', '') for model in models 
                   if 'generateContent' in model.supported_generation_methods]
        
        elif provider == "OpenAI":
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            model_names = [model.id for model in models.data 
                          if any(keyword in model.id.lower() for keyword in ['gpt', 'vision', 'turbo'])]
            return sorted(model_names, reverse=True)
        
        elif provider == "Anthropic":
            # Anthropicã®APIã¯ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æä¾›ã—ã¦ã„ãªã„ãŸã‚ã€æ—¢çŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
            return [
                "claude-3-5-sonnet-20241022",
                "claude-3-5-haiku-20241022", 
                "claude-3-opus-20240229",
                "claude-3-sonnet-20240229",
                "claude-3-haiku-20240307"
            ]
        
        return []
        
    except Exception as e:
        st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—: {str(e)}")
        return []

def get_models_with_cache(provider, api_key):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    if not api_key:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])
    
    try:
        available_models = fetch_available_models(provider, api_key)
        return available_models if available_models else DEFAULT_MODEL_OPTIONS.get(provider, [])
    except:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])

def load_schema(file_path=None, file_content=None):
    """ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                schema = json.load(f)
                st.success(f"âœ… ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿å®Œäº†: {len(schema.get('properties', {}))} ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£")
                return schema
        elif file_content:
            schema = json.loads(file_content)
            st.success(f"âœ… ã‚¹ã‚­ãƒ¼ãƒè§£æå®Œäº†: {len(schema.get('properties', {}))} ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£")
            return schema
        return {}
    except Exception as e:
        st.error(f"âŒ ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

def detect_domain_only(pdf_path, model_name, api_key):
    """ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿å®Ÿè¡Œ"""
    try:
        if not EXTRACTOR_AVAILABLE:
            return {"error": "æŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
            
        extractor = PatentExtractor(
            model_name=model_name,
            api_key=api_key,
            temperature=0.1,
            max_tokens=2048
        )
        return extractor.detect_domain_parallel(pdf_path)
    except Exception as e:
        return {"error": str(e)}

def process_pdf_parallel(pdf_path, model_name, api_key, schema, prompt=None, temperature=0.1, max_tokens=8192, max_workers=8):
    """ä¸¦åˆ—å‡¦ç†ã§PDFã‚’å‡¦ç†"""
    try:
        if not EXTRACTOR_AVAILABLE:
            return {"error": "æŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
            
        extractor = PatentExtractor(
            model_name=model_name,
            api_key=api_key,
            json_schema=schema,
            temperature=temperature,
            max_tokens=max_tokens,
            max_workers=max_workers
        )
        return extractor.process_patent_parallel(pdf_path)
    except Exception as e:
        return {"error": str(e)}

def save_upload_file(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getbuffer())
            return tmp.name
    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def display_domain_info(domain_info):
    """ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±ã‚’è¡¨ç¤º"""
    if not domain_info or "error" in domain_info:
        return
    
    domain = domain_info.get("primary_domain", "unknown")
    
    # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒƒã‚¸
    domain_colors = {
        "chemical": "#FF6B6B",
        "biotechnology": "#4ECDC4", 
        "mechanical": "#45B7D1",
        "electrical": "#96CEB4",
        "software": "#FFEAA7",
        "general": "#DDA0DD"
    }
    
    color = domain_colors.get(domain, "#DDA0DD")
    st.markdown(f"""
    <div style="background: {color}; color: white; padding: 10px; border-radius: 5px; text-align: center; margin: 10px 0;">
        ğŸ” æ¤œå‡ºãƒ‰ãƒ¡ã‚¤ãƒ³: <strong>{domain.upper()}</strong>
    </div>
    """, unsafe_allow_html=True)

def display_performance_metrics(processing_metadata):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’è¡¨ç¤º"""
    if not processing_metadata:
        return
    
    st.markdown("### ğŸ“Š å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
    
    total_time = processing_metadata.get("total_time_seconds", 0)
    workers = processing_metadata.get("parallel_workers", 1)
    stats = processing_metadata.get("processing_stats", {})
    field_timing = processing_metadata.get("field_timing", {})
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("â±ï¸ ç·å‡¦ç†æ™‚é–“", f"{total_time:.1f}ç§’")
    
    with col2:
        st.metric("ğŸš€ ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼", f"{workers}")
    
    with col3:
        successful = stats.get("successful_fields", 0)
        total = stats.get("total_fields", 0)
        success_rate = (successful / max(1, total)) * 100
        st.metric("âœ… æˆåŠŸç‡", f"{success_rate:.1f}%")
    
    with col4:
        if field_timing:
            estimated_sequential = sum(field_timing.values())
            speedup = estimated_sequential / total_time if total_time > 0 else 1
            st.metric("âš¡ é«˜é€ŸåŒ–", f"{speedup:.1f}x")
        else:
            st.metric("âš¡ é«˜é€ŸåŒ–", "N/A")
    
    # è©³ç´°ã‚¿ã‚¤ãƒŸãƒ³ã‚°
    if field_timing:
        with st.expander("ğŸ“ˆ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¥å‡¦ç†æ™‚é–“"):
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            timing_df = pd.DataFrame([
                {"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰": field, "å‡¦ç†æ™‚é–“(ç§’)": timing}
                for field, timing in sorted(field_timing.items(), key=lambda x: x[1], reverse=True)
            ])
            
            # ã‚°ãƒ©ãƒ•è¡¨ç¤º
            fig = px.bar(timing_df, x="ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰", y="å‡¦ç†æ™‚é–“(ç§’)", 
                        title="ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¥å‡¦ç†æ™‚é–“",
                        color="å‡¦ç†æ™‚é–“(ç§’)",
                        color_continuous_scale="viridis")
            fig.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.dataframe(timing_df, use_container_width=True)

def display_validation_results(result, schema):
    """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¡¨ç¤º"""
    if not schema:
        return
    
    st.markdown("### ğŸ” ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼çµæœ")
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
    required_fields = schema.get("required", [])
    schema_properties = schema.get("properties", {})
    
    present_required = [f for f in required_fields if f in result and result[f] is not None]
    missing_required = [f for f in required_fields if f not in result or result[f] is None]
    
    optional_present = [f for f in schema_properties if f not in required_fields and f in result and result[f] is not None]
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
        <div class="success-metrics">
            <h4>âœ… å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰</h4>
            <h2>{len(present_required)}/{len(required_fields)}</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ“‹ ã‚ªãƒ—ã‚·ãƒ§ãƒ³</h4>
            <h2>{len(optional_present)}</h2>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        total_coverage = (len(present_required) + len(optional_present)) / max(1, len(schema_properties)) * 100
        coverage_class = "success-metrics" if total_coverage > 80 else "error-metrics" if total_coverage < 50 else "metric-card"
        st.markdown(f"""
        <div class="{coverage_class}">
            <h4>ğŸ“Š ã‚«ãƒãƒ¬ãƒƒã‚¸</h4>
            <h2>{total_coverage:.1f}%</h2>
        </div>
        """, unsafe_allow_html=True)
    
    # ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    if missing_required:
        with st.expander("âŒ ä¸è¶³å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰"):
            for field in missing_required:
                st.error(f"â€¢ {field}")

def display_extraction_summary(result):
    """æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    clean_result = {k: v for k, v in result.items() if not k.startswith('_')}
    
    st.markdown("### ğŸ“‹ æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çµ±è¨ˆ
    total_fields = len(clean_result)
    successful_fields = len([v for v in clean_result.values() if not (isinstance(v, dict) and 'error' in v)])
    error_fields = total_fields - successful_fields
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“Š ç·ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰", total_fields)
    with col2:
        st.metric("âœ… æˆåŠŸ", successful_fields)
    with col3:
        st.metric("âŒ ã‚¨ãƒ©ãƒ¼", error_fields)
    
    # ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å†…å®¹ãƒã‚§ãƒƒã‚¯
    key_fields_status = {}
    key_fields = ["publicationIdentifier", "FrontPage", "Claims", "Description", "ChemicalStructureLibrary", "BiologicalSequenceLibrary"]
    
    for field in key_fields:
        if field in clean_result:
            value = clean_result[field]
            if isinstance(value, dict) and "error" in value:
                key_fields_status[field] = "âŒ ã‚¨ãƒ©ãƒ¼"
            elif value is None:
                key_fields_status[field] = "âšª ç©º"
            else:
                key_fields_status[field] = "âœ… æˆåŠŸ"
        else:
            key_fields_status[field] = "â– ãªã—"
    
    with st.expander("ğŸ” ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çŠ¶æ³"):
        for field, status in key_fields_status.items():
            st.write(f"**{field}**: {status}")

# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸš€ ä¸¦åˆ—ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«")
st.markdown("**AIä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€Ÿç‰¹è¨±ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ **")

if not EXTRACTOR_AVAILABLE:
    st.error("âŒ æŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ å‡¦ç†è¨­å®š")
    
    # ä¸¦åˆ—å‡¦ç†è¨­å®š
    st.subheader("ğŸš€ ä¸¦åˆ—å‡¦ç†")
    max_workers = st.slider("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°", 1, 32, 8, help="åŒæ™‚å‡¦ç†ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°")
    
    processing_mode = st.radio(
        "å‡¦ç†ãƒ¢ãƒ¼ãƒ‰",
        ["ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿", "âš¡ å®Œå…¨ä¸¦åˆ—æŠ½å‡º"],
        help="ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿ã¯é«˜é€Ÿã€å®Œå…¨æŠ½å‡ºã¯è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"
    )
    
    # AIãƒ¢ãƒ‡ãƒ«è¨­å®š
    st.subheader("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«")
    provider = st.selectbox("ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", list(DEFAULT_MODEL_OPTIONS.keys()))
    api_key = st.text_input(
        f"{provider} APIã‚­ãƒ¼", 
        value=get_api_key_from_env(provider), 
        type="password",
        help="ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®è‡ªå‹•å–å¾—ã‚‚ã‚µãƒãƒ¼ãƒˆ"
    )
    
    # ãƒ¢ãƒ‡ãƒ«å–å¾—ã¨é¸æŠ
    if api_key:
        with st.spinner("ğŸ”„ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ä¸­..."):
            available_models = get_models_with_cache(provider, api_key)
        
        if available_models:
            st.success(f"âœ… {len(available_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—")
            model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«", available_models)
            
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒœã‚¿ãƒ³
            if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æ›´æ–°"):
                st.cache_data.clear()
                st.rerun()
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            model_name = ""
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        model_name = ""
    
    # ã‚¹ã‚­ãƒ¼ãƒè¨­å®š
    st.subheader("ğŸ“‹ JSONã‚¹ã‚­ãƒ¼ãƒ")
    schema_type = st.radio("ã‚¹ã‚­ãƒ¼ãƒè¨­å®š", ["ğŸ¯ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«", "âœï¸ ç›´æ¥å…¥åŠ›"])
    
    schema = {}
    if schema_type == "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«":
        uploaded_schema = st.file_uploader("ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«", type=["json"])
        if uploaded_schema:
            schema = load_schema(file_content=uploaded_schema.getvalue().decode("utf-8"))
    elif schema_type == "âœï¸ ç›´æ¥å…¥åŠ›":
        schema_text = st.text_area("JSONã‚¹ã‚­ãƒ¼ãƒ", height=150, placeholder='{"type": "object", "properties": {...}}')
        if schema_text:
            try:
                schema = json.loads(schema_text)
                st.success("âœ… ã‚¹ã‚­ãƒ¼ãƒå½¢å¼OK")
            except:
                st.error("âŒ JSONå½¢å¼ã‚¨ãƒ©ãƒ¼")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒ
        default_paths = ["default_schema.json", "schema.json", "./default_schema.json"]
        for path in default_paths:
            if os.path.exists(path):
                schema = load_schema(file_path=path)
                break
        if not schema:
            st.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # è©³ç´°è¨­å®š
    with st.expander("âš™ï¸ è©³ç´°è¨­å®š"):
        custom_prompt = st.text_area("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", height=80, placeholder="è¿½åŠ ã®æŠ½å‡ºæŒ‡ç¤º...")
        temperature = st.slider("Temperature", 0.0, 1.0, 0.1, 0.05, help="0.0=æ±ºå®šçš„, 1.0=å‰µé€ çš„")
        max_tokens = st.selectbox("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", [2048, 4096, 8192, 16384, 32768], index=2)

# ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒªã‚¢
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¥ å…¥åŠ›")
    
    uploaded_pdf = st.file_uploader(
        "ç‰¹è¨±PDFãƒ•ã‚¡ã‚¤ãƒ«", 
        type=["pdf"],
        help="æ—¥æœ¬èªãƒ»è‹±èªã®ç‰¹è¨±PDFã«å¯¾å¿œ"
    )
    
    if uploaded_pdf:
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_pdf.name} ({uploaded_pdf.size:,} bytes)")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        with st.expander("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°"):
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å**: {uploaded_pdf.name}")
            st.write(f"**ã‚µã‚¤ã‚º**: {uploaded_pdf.size:,} bytes")
            st.write(f"**ã‚¿ã‚¤ãƒ—**: {uploaded_pdf.type}")
    
    # å‡¦ç†ãƒœã‚¿ãƒ³
    process_enabled = uploaded_pdf and api_key and model_name
    
    if processing_mode == "ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿":
        process_button = st.button(
            "ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºå®Ÿè¡Œ",
            disabled=not process_enabled,
            use_container_width=True,
            help="é«˜é€Ÿã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿æ¤œå‡º"
        )
    else:
        process_button = st.button(
            f"âš¡ ä¸¦åˆ—æŠ½å‡ºé–‹å§‹ ({max_workers}workers)",
            disabled=not process_enabled,
            use_container_width=True,
            help="å®Œå…¨ãªä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"
        )
    
    if not process_enabled:
        missing = []
        if not uploaded_pdf: missing.append("PDFãƒ•ã‚¡ã‚¤ãƒ«")
        if not api_key: missing.append("APIã‚­ãƒ¼")
        if not model_name: missing.append("ãƒ¢ãƒ‡ãƒ«é¸æŠ")
        st.warning(f"âš ï¸ ä¸è¶³: {', '.join(missing)}")

with col2:
    st.header("ğŸ“¤ å‡ºåŠ›")
    
    if process_button and uploaded_pdf and api_key and model_name:
        pdf_path = save_upload_file(uploaded_pdf)
        
        if pdf_path:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                if processing_mode == "ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿":
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿
                    status_text.text("ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºä¸­...")
                    progress_bar.progress(50)
                    
                    result = detect_domain_only(pdf_path, model_name, api_key)
                    progress_bar.progress(100)
                    
                    if "error" in result:
                        st.error(f"âŒ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {result['error']}")
                    else:
                        st.success("âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºå®Œäº†ï¼")
                        display_domain_info(result)
                        
                        # çµæœè¡¨ç¤º
                        st.json(result)
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        json_str = json.dumps(result, indent=2, ensure_ascii=False)
                        st.download_button(
                            "ğŸ“¥ ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_str.encode("utf-8"),
                            file_name=f"{Path(uploaded_pdf.name).stem}_domain.json",
                            mime="application/json",
                            use_container_width=True
                        )
                
                else:
                    # å®Œå…¨ä¸¦åˆ—æŠ½å‡º
                    status_text.text(f"âš¡ {model_name}ã§ä¸¦åˆ—å‡¦ç†ä¸­...")
                    progress_bar.progress(25)
                    
                    start_time = time.time()
                    result = process_pdf_parallel(
                        pdf_path=pdf_path,
                        model_name=model_name,
                        api_key=api_key,
                        schema=schema,
                        prompt=custom_prompt if custom_prompt else None,
                        temperature=temperature,
                        max_tokens=max_tokens,
                        max_workers=max_workers
                    )
                    
                    progress_bar.progress(100)
                    
                    if "error" in result:
                        st.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
                    else:
                        st.success("âœ… ä¸¦åˆ—å‡¦ç†å®Œäº†ï¼")
                        
                        # ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±è¡¨ç¤º
                        if "_processing_metadata" in result:
                            domain = result["_processing_metadata"].get("domain_detected")
                            if domain:
                                display_domain_info({"primary_domain": domain})
                        
                        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
                        if "_processing_metadata" in result:
                            display_performance_metrics(result["_processing_metadata"])
                        
                        # æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼
                        display_extraction_summary(result)
                        
                        # ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
                        if schema:
                            display_validation_results(result, schema)
                        
                        # çµæœè¡¨ç¤º
                        clean_result = {k: v for k, v in result.items() if not k.startswith('_')}
                        
                        with st.expander("ğŸ“‹ å®Œå…¨ãªæŠ½å‡ºçµæœ"):
                            st.json(clean_result)
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        col_dl1, col_dl2 = st.columns(2)
                        
                        with col_dl1:
                            json_str = json.dumps(clean_result, indent=2, ensure_ascii=False)
                            output_filename = f"{Path(uploaded_pdf.name).stem}_extracted.json"
                            
                            st.download_button(
                                "ğŸ“¥ æŠ½å‡ºçµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=json_str.encode("utf-8"),
                                file_name=output_filename,
                                mime="application/json",
                                use_container_width=True
                            )
                        
                        with col_dl2:
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãå®Œå…¨ç‰ˆ
                            full_json_str = json.dumps(result, indent=2, ensure_ascii=False)
                            metadata_filename = f"{Path(uploaded_pdf.name).stem}_full.json"
                            
                            st.download_button(
                                "ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=full_json_str.encode("utf-8"),
                                file_name=metadata_filename,
                                mime="application/json",
                                use_container_width=True
                            )
                
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                try:
                    os.remove(pdf_path)
                except:
                    pass
                
                status_text.empty()
                progress_bar.empty()
    
    else:
        # å¾…æ©ŸçŠ¶æ…‹ã®æƒ…å ±è¡¨ç¤º
        st.info("ğŸ“‹ PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
        
        # ä½¿ç”¨ä¾‹è¡¨ç¤º
        with st.expander("ğŸ’¡ å‡ºåŠ›ä¾‹"):
            if processing_mode == "ğŸ” ãƒ‰ãƒ¡ã‚¤ãƒ³æ¤œå‡ºã®ã¿":
                example = {
                    "primary_domain": "chemical",
                    "structural_elements": ["chemical_structures", "tables", "figures"],
                    "extraction_priorities": ["ChemicalStructureLibrary", "Claims", "Description"],
                    "complexity_level": "high"
                }
            else:
                example = {
                    "publicationIdentifier": "WO2024123456A1",
                    "FrontPage": {
                        "PublicationData": {"PublicationNumber": "WO2024123456A1"},
                        "Abstract": {"Paragraph": [{"content": "AIç‰¹è¨±æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ..."}]}
                    },
                    "Claims": {"Claim": [{"id": "1", "Text": {"content": "AIã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•..."}}]},
                    "ChemicalStructureLibrary": {"Compound": []}
                }
            st.json(example)

# ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
st.markdown("---")
col_info1, col_info2, col_info3 = st.columns(3)

with col_info1:
    st.markdown("**ğŸš€ æ©Ÿèƒ½**")
    st.markdown("â€¢ ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸæŠ½å‡º")
    st.markdown("â€¢ ãƒ‰ãƒ¡ã‚¤ãƒ³è‡ªå‹•æ¤œå‡º")
    st.markdown("â€¢ ã‚¹ã‚­ãƒ¼ãƒæº–æ‹ ")

with col_info2:
    st.markdown("**ğŸ“Š å¯¾å¿œãƒ‰ãƒ¡ã‚¤ãƒ³**") 
    st.markdown("â€¢ åŒ–å­¦ãƒ»åŒ»è–¬")
    st.markdown("â€¢ ãƒã‚¤ã‚ªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼")
    st.markdown("â€¢ æ©Ÿæ¢°ãƒ»é›»å­")

with col_info3:
    st.markdown("**âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**")
    st.markdown("â€¢ æœ€å¤§32ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼")
    st.markdown("â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º")
    st.markdown("â€¢ è©³ç´°çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ")

st.markdown(
    "<div style='text-align: center; color: #666; margin-top: 20px;'>"
    "ğŸ”¬ ä¸¦åˆ—ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ« - AIé§†å‹•é«˜é€Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ "
    "</div>", 
    unsafe_allow_html=True
)