import streamlit as st
import json
import os
import tempfile
from pathlib import Path
from pypdf import PdfReader, PdfWriter
from typing import Dict, List, Any

from patent_extractor import PatentExtractor

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
    }
    .stButton button {
        width: 100%;
    }
    .json-display {
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 10px;
        background-color: #f5f5f5;
        height: 500px;
        overflow: auto;
    }
    .stat-box {
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 10px;
        text-align: center;
    }
    .blue-stat {
        background-color: #f0f5ff;
        border: 1px solid #d0e0ff;
    }
    .green-stat {
        background-color: #f0fff5;
        border: 1px solid #d0ffe0;
    }
    .orange-stat {
        background-color: #fff5f0;
        border: 1px solid #ffe0d0;
    }
    .title-area {
        text-align: center;
        margin-bottom: 2rem;
    }
    .page-progress {
        margin: 10px 0;
        padding: 10px;
        border-radius: 5px;
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
    }
    .error-page {
        background-color: #fff5f5;
        border-left: 4px solid #dc3545;
    }
    .success-page {
        background-color: #f0fff4;
        border-left: 4px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é¸æŠè‚¢ï¼‰
DEFAULT_MODEL_OPTIONS = {
    "Google Gemini": ["gemini-1.5-pro", "gemini-1.5-flash"],
    "OpenAI": ["gpt-4o", "gpt-4-vision-preview"],
    "Anthropic": ["claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
}

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_api_key_from_env(provider):
    if provider == "Google Gemini":
        return os.environ.get("GOOGLE_API_KEY", "")
    elif provider == "OpenAI":
        return os.environ.get("OPENAI_API_KEY", "")
    elif provider == "Anthropic":
        return os.environ.get("ANTHROPIC_API_KEY", "")
    return ""

# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æ¨å®šã™ã‚‹é–¢æ•°
def get_model_prefix(provider):
    if provider == "Google Gemini":
        return "gemini-"
    elif provider == "OpenAI":
        return "gpt-"
    elif provider == "Anthropic":
        return "claude-"
    return ""

# ãƒ¢ãƒ‡ãƒ«åãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹é–¢æ•°
def is_valid_model_name(model_name, provider):
    """ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«é©ã—ã¦ã„ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not model_name:
        return False
    
    model_lower = model_name.lower()
    
    if provider == "Google Gemini":
        return "gemini" in model_lower
    elif provider == "OpenAI":
        return "gpt" in model_lower or "openai" in model_lower
    elif provider == "Anthropic":
        return "claude" in model_lower
    
    return True  # ãã®ä»–ã®å ´åˆã¯é€šã™

# APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã™ã‚‹é–¢æ•°
@st.cache_data(ttl=3600)  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def fetch_available_models(provider, api_key):
    """APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        if not api_key:
            return []
        
        if provider == "Google Gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models = genai.list_models()
            return [model.name.replace('models/', '') for model in models 
                   if 'generateContent' in model.supported_generation_methods]
        
        elif provider == "OpenAI":
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            # GPTãƒ¢ãƒ‡ãƒ«ã¨ Visionå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            model_names = [model.id for model in models.data 
                          if 'gpt' in model.id.lower() or 'vision' in model.id.lower()]
            return sorted(model_names, reverse=True)  # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ã‚½ãƒ¼ãƒˆ
        
        elif provider == "Anthropic":
            # Anthropicã®APIã¯ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æä¾›ã—ã¦ã„ãªã„ãŸã‚ã€æ—¢çŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
            return [
                "claude-3-opus-20240229",
                "claude-3-sonnet-20240229", 
                "claude-3-haiku-20240307",
                "claude-3-5-sonnet-20241022",
                "claude-3-5-haiku-20241022"
            ]
        
        return []
        
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹é–¢æ•°
def get_models_with_cache(provider, api_key):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    if not api_key:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])
    
    try:
        available_models = fetch_available_models(provider, api_key)
        if available_models:
            return available_models
        else:
            # APIã§å–å¾—ã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
            return DEFAULT_MODEL_OPTIONS.get(provider, [])
    except:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])

# JSONã‚¹ã‚­ãƒ¼ãƒã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
def load_schema(file_path=None, file_content=None):
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        elif file_content:
            return json.loads(file_content)
        return {}
    except Exception as e:
        st.error(f"JSONã‚¹ã‚­ãƒ¼ãƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

# PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤åˆ†å‰²ã—ã¦å‡¦ç†ã™ã‚‹é–¢æ•°
def split_pdf_to_pages(pdf_path: str) -> List[str]:
    """PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤åˆ†å‰²ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    page_paths = []
    try:
        reader = PdfReader(pdf_path)
        
        for page_num in range(len(reader.pages)):
            # æ–°ã—ã„PDFãƒ©ã‚¤ã‚¿ãƒ¼ã‚’ä½œæˆ
            writer = PdfWriter()
            writer.add_page(reader.pages[page_num])
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            temp_path = tempfile.mktemp(suffix=f"_page_{page_num + 1}.pdf")
            with open(temp_path, "wb") as output_file:
                writer.write(output_file)
            
            page_paths.append(temp_path)
        
        return page_paths
    except Exception as e:
        st.error(f"PDFåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

# 1ãƒšãƒ¼ã‚¸ã®PDFã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
def process_single_page(page_path: str, page_num: int, model_name: str, api_key: str, 
                       schema: Dict, prompt: str = None, temperature: float = 0.1, 
                       max_tokens: int = 4096) -> Dict:
    """1ãƒšãƒ¼ã‚¸ã®PDFã‚’å‡¦ç†"""
    try:
        extractor = PatentExtractor(
            model_name=model_name,
            api_key=api_key,
            json_schema=schema,
            user_prompt=prompt,
            temperature=temperature,
            max_tokens=max_tokens
        )
        result = extractor.process_patent_pdf(page_path)
        return {
            "page_number": page_num,
            "status": "success",
            "data": result
        }
    except Exception as e:
        return {
            "page_number": page_num,
            "status": "error",
            "error": str(e),
            "data": {}
        }

# è¤‡æ•°ãƒšãƒ¼ã‚¸ã®çµæœã‚’çµ±åˆã™ã‚‹é–¢æ•°
def merge_page_results(page_results: List[Dict]) -> Dict:
    """è¤‡æ•°ãƒšãƒ¼ã‚¸ã®çµæœã‚’çµ±åˆã—ã¦ã²ã¨ã¤ã®JSONã‚’ä½œæˆ"""
    merged_result = {
        "processing_summary": {
            "total_pages": len(page_results),
            "successful_pages": sum(1 for r in page_results if r["status"] == "success"),
            "failed_pages": sum(1 for r in page_results if r["status"] == "error"),
            "page_details": []
        }
    }
    
    # å„ãƒšãƒ¼ã‚¸ã®è©³ç´°ã‚’è¨˜éŒ²
    for result in page_results:
        page_detail = {
            "page_number": result["page_number"],
            "status": result["status"]
        }
        if result["status"] == "error":
            page_detail["error"] = result["error"]
        merged_result["processing_summary"]["page_details"].append(page_detail)
    
    # æˆåŠŸã—ãŸãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
    successful_results = [r["data"] for r in page_results if r["status"] == "success"]
    
    if not successful_results:
        merged_result["error"] = "ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã§å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"
        return merged_result
    
    # åŸºæœ¬çš„ãªçµ±åˆæˆ¦ç•¥
    # 1. publicationIdentifierã¯æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
    # 2. ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯é…åˆ—ã¨ã—ã¦çµ±åˆ
    # 3. å˜ä¸€å€¤ã¯æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
    
    for i, result in enumerate(successful_results):
        if i == 0:
            # æœ€åˆã®çµæœã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨
            for key, value in result.items():
                if key not in merged_result:
                    merged_result[key] = value
        else:
            # å¾Œç¶šã®çµæœã‚’ãƒãƒ¼ã‚¸
            for key, value in result.items():
                if key in merged_result:
                    # æ—¢å­˜ã®ã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã®çµ±åˆãƒ­ã‚¸ãƒƒã‚¯
                    if isinstance(merged_result[key], dict) and isinstance(value, dict):
                        # è¾æ›¸ã®å ´åˆã¯å†å¸°çš„ã«ãƒãƒ¼ã‚¸
                        merged_result[key] = merge_dict_values(merged_result[key], value)
                    elif isinstance(merged_result[key], list) and isinstance(value, list):
                        # ãƒªã‚¹ãƒˆã®å ´åˆã¯çµåˆ
                        merged_result[key].extend(value)
                    # å˜ä¸€å€¤ã®å ´åˆã¯æœ€åˆã®å€¤ã‚’ä¿æŒï¼ˆä¸Šæ›¸ãã—ãªã„ï¼‰
                else:
                    # æ–°ã—ã„ã‚­ãƒ¼ã®å ´åˆã¯è¿½åŠ 
                    merged_result[key] = value
    
    return merged_result

def merge_dict_values(dict1: Dict, dict2: Dict) -> Dict:
    """è¾æ›¸ã®å€¤ã‚’å†å¸°çš„ã«ãƒãƒ¼ã‚¸"""
    result = dict1.copy()
    
    for key, value in dict2.items():
        if key in result:
            if isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = merge_dict_values(result[key], value)
            elif isinstance(result[key], list) and isinstance(value, list):
                result[key].extend(value)
            # å˜ä¸€å€¤ã®å ´åˆã¯æœ€åˆã®å€¤ã‚’ä¿æŒ
        else:
            result[key] = value
    
    return result

# ãƒšãƒ¼ã‚¸å˜ä½ã§PDFã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
def process_pdf_by_pages(pdf_path: str, model_name: str, api_key: str, schema: Dict, 
                        prompt: str = None, temperature: float = 0.1, 
                        max_tokens: int = 4096, progress_container=None) -> Dict:
    """PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤å‡¦ç†ã—ã¦çµæœã‚’çµ±åˆ"""
    try:
        # PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤åˆ†å‰²
        page_paths = split_pdf_to_pages(pdf_path)
        
        if not page_paths:
            return {"error": "PDFã®åˆ†å‰²ã«å¤±æ•—ã—ã¾ã—ãŸ"}
        
        total_pages = len(page_paths)
        page_results = []
        
        # é€²æ—è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
        if progress_container:
            progress_bar = progress_container.progress(0)
            status_text = progress_container.empty()
        
        try:
            # å„ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†
            for i, page_path in enumerate(page_paths):
                page_num = i + 1
                
                # é€²æ—æ›´æ–°
                if progress_container:
                    progress = (i + 1) / total_pages
                    progress_bar.progress(progress)
                    status_text.text(f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‚’å‡¦ç†ä¸­...")
                
                # ãƒšãƒ¼ã‚¸å‡¦ç†
                result = process_single_page(
                    page_path, page_num, model_name, api_key, schema, 
                    prompt, temperature, max_tokens
                )
                
                page_results.append(result)
                
                # é€²æ—è¡¨ç¤ºã®æ›´æ–°
                if progress_container:
                    with progress_container:
                        if result["status"] == "success":
                            st.markdown(f'<div class="page-progress success-page">âœ… ãƒšãƒ¼ã‚¸ {page_num}: å‡¦ç†å®Œäº†</div>', unsafe_allow_html=True)
                        else:
                            st.markdown(f'<div class="page-progress error-page">âŒ ãƒšãƒ¼ã‚¸ {page_num}: ã‚¨ãƒ©ãƒ¼ - {result["error"]}</div>', unsafe_allow_html=True)
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
            for page_path in page_paths:
                try:
                    os.remove(page_path)
                except:
                    pass
        
        # é€²æ—å®Œäº†
        if progress_container:
            progress_bar.progress(1.0)
            status_text.text("å…¨ãƒšãƒ¼ã‚¸ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # çµæœã‚’çµ±åˆ
        merged_result = merge_page_results(page_results)
        
        return merged_result
        
    except Exception as e:
        return {"error": f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"}

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹é–¢æ•°
def save_upload_file(uploaded_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getbuffer())
            return tmp.name
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.markdown('<div class="title-area">', unsafe_allow_html=True)
st.title("ğŸ§© ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«")
st.markdown("""
ç‰¹è¨±PDFã‹ã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”ŸæˆAIã‚’ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–JSONã‚’æŠ½å‡ºã—ã¾ã™ã€‚
Geminiã€GPTã€Claudeãªã©ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã§ãã¾ã™ã€‚
**ğŸ“„ ãƒšãƒ¼ã‚¸å˜ä½å‡¦ç†**: PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤å‡¦ç†ã—ã¦çµæœã‚’çµ±åˆã—ã¾ã™ã€‚
""")
st.markdown('</div>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ - è¨­å®šã‚¨ãƒªã‚¢
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠ
    provider = st.selectbox(
        "AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆGoogle Geminiã‚’æ¨å¥¨ï¼‰",
        options=list(DEFAULT_MODEL_OPTIONS.keys())
    )
    
    # APIã‚­ãƒ¼å…¥åŠ›ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã®ãŸã‚ã«å…ˆã«é…ç½®ï¼‰
    api_key = st.text_input(
        f"{provider} APIã‚­ãƒ¼",
        value=get_api_key_from_env(provider),
        type="password",
        help="APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•çš„ã«å–å¾—ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚"
    )
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠæ–¹æ³•ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³
    model_input_type = st.radio(
        "ãƒ¢ãƒ‡ãƒ«é¸æŠæ–¹æ³•",
        options=["åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ", "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›"],
        horizontal=True
    )
    
    if model_input_type == "åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ":
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        with st.spinner("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ä¸­..."):
            available_models = get_models_with_cache(provider, api_key)
        
        if available_models:
            # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®æƒ…å ±è¡¨ç¤º
            if api_key:
                st.info(f"âœ… {len(available_models)}å€‹ã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ")
            else:
                st.info(f"â„¹ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤ºä¸­ï¼ˆAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã™ã‚‹ã¨æœ€æ–°ä¸€è¦§ã‚’å–å¾—ï¼‰")
            
            model_name = st.selectbox(
                "ãƒ¢ãƒ‡ãƒ«",
                options=available_models,
                help="APIã‹ã‚‰å–å¾—ã—ãŸåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã§ã™"
            )
            
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒœã‚¿ãƒ³
            if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æ›´æ–°", help="æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å†å–å¾—ã—ã¾ã™"):
                st.cache_data.clear()  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                st.rerun()  # ã‚¢ãƒ—ãƒªã‚’å†å®Ÿè¡Œ
                
        else:
            st.error("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            model_name = ""
            
    else:
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«åã‚’ç›´æ¥å…¥åŠ›
        model_placeholder = get_model_prefix(provider) + "model-name"
        model_name = st.text_input(
            "ãƒ¢ãƒ‡ãƒ«å",
            placeholder=model_placeholder,
            help=f"{provider}ã®ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: {model_placeholder}ï¼‰"
        )
        
        # ãƒ¢ãƒ‡ãƒ«åã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if model_name and not is_valid_model_name(model_name, provider):
            st.warning(f"âš ï¸ å…¥åŠ›ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åã€Œ{model_name}ã€ã¯{provider}ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒ’ãƒ³ãƒˆè¡¨ç¤º
        with st.expander("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«åã®ãƒ’ãƒ³ãƒˆ"):
            if provider == "Google Gemini":
                st.markdown("""
                **Google Geminiãƒ¢ãƒ‡ãƒ«ä¾‹:**
                - `gemini-1.5-pro` - é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
                - `gemini-1.5-flash` - é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
                - `gemini-2.0-flash-exp` - å®Ÿé¨“çš„ãƒ¢ãƒ‡ãƒ«
                """)
            elif provider == "OpenAI":
                st.markdown("""
                **OpenAIãƒ¢ãƒ‡ãƒ«ä¾‹:**
                - `gpt-4o` - æœ€æ–°ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«
                - `gpt-4-vision-preview` - ãƒ“ã‚¸ãƒ§ãƒ³å¯¾å¿œãƒ¢ãƒ‡ãƒ«
                - `gpt-4-turbo` - é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
                """)
            elif provider == "Anthropic":
                st.markdown("""
                **Anthropicãƒ¢ãƒ‡ãƒ«ä¾‹:**
                - `claude-3-opus-20240229` - æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
                - `claude-3-sonnet-20240229` - ãƒãƒ©ãƒ³ã‚¹å‹ãƒ¢ãƒ‡ãƒ«
                - `claude-3-haiku-20240307` - é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
                - `claude-3-5-sonnet-20241022` - æœ€æ–°Sonnetãƒ¢ãƒ‡ãƒ«
                """)
    
    # ãƒ¢ãƒ‡ãƒ«åãŒç©ºã®å ´åˆã®è­¦å‘Š
    if model_input_type == "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›" and not model_name:
        st.error("ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±è¡¨ç¤º
    if model_name:
        st.success(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«: **{model_name}**")
    
    # ã‚¹ã‚­ãƒ¼ãƒã‚¿ã‚¤ãƒ—ã®é¸æŠ
    schema_type = st.radio(
        "JSONã‚¹ã‚­ãƒ¼ãƒ",
        options=["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨", "ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ã‚¹ã‚­ãƒ¼ãƒã‚’ç›´æ¥å…¥åŠ›"],
        index=0
    )
    
    schema = {}
    if schema_type == "ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_schema = st.file_uploader(
            "JSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«",
            type=["json"],
            help="JSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        if uploaded_schema:
            schema_content = uploaded_schema.getvalue().decode("utf-8")
            schema = load_schema(file_content=schema_content)
            if schema:
                st.success("ã‚¹ã‚­ãƒ¼ãƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    elif schema_type == "ã‚¹ã‚­ãƒ¼ãƒã‚’ç›´æ¥å…¥åŠ›":
        schema_text = st.text_area(
            "JSONã‚¹ã‚­ãƒ¼ãƒã‚’å…¥åŠ›",
            height=200,
            help="JSONã‚¹ã‚­ãƒ¼ãƒã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        if schema_text:
            try:
                schema = json.loads(schema_text)
                st.success("ã‚¹ã‚­ãƒ¼ãƒã®å½¢å¼ãŒæ­£ã—ã„ã§ã™")
            except json.JSONDecodeError:
                st.error("JSONã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    
    else:  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨
        default_schema_path = "default_schema.json"
        if os.path.exists(default_schema_path):
            schema = load_schema(file_path=default_schema_path)
            st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            st.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç©ºã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¾ã™")
    
    # è©³ç´°è¨­å®š
    with st.expander("è©³ç´°è¨­å®š", expanded=False):
        custom_prompt = st.text_area(
            "ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="",
            height=100,
            help="ç”ŸæˆAIã¸ã®ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã‚’å…¥åŠ›ã§ãã¾ã™"
        )
        
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=1.0,
            value=0.1,
            step=0.05,
            help="é«˜ã„å€¤: ã‚ˆã‚Šå¤šæ§˜ãªå‡ºåŠ›ã€ä½ã„å€¤: ã‚ˆã‚Šç¢ºå®šçš„ãªå‡ºåŠ›"
        )
        
        max_tokens = st.number_input(
            "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
            min_value=1024,
            max_value=65535,
            value=32768,
            step=1024,
            help="ç”ŸæˆAIãŒå‡ºåŠ›ã§ãã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
        )
    
    # ã‚¹ã‚­ãƒ¼ãƒã®è©³ç´°è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if schema and st.checkbox("ã‚¹ã‚­ãƒ¼ãƒè©³ç´°ã‚’è¡¨ç¤º"):
        st.json(schema)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ - 2åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¤ å…¥åŠ›")
    
    # PDF ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_pdf = st.file_uploader(
        "ç‰¹è¨±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["pdf"],
        help="å‡¦ç†ã™ã‚‹ç‰¹è¨±PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_pdf:
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«å: {uploaded_pdf.name}")
        
        # PDFã®åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
        try:
            # PDFã‚’ä¸€æ™‚ä¿å­˜ã—ã¦ãƒšãƒ¼ã‚¸æ•°ã‚’å–å¾—
            temp_pdf_path = save_upload_file(uploaded_pdf)
            if temp_pdf_path:
                reader = PdfReader(temp_pdf_path)
                page_count = len(reader.pages)
                os.remove(temp_pdf_path)
                
                st.info(f"ğŸ“„ ç·ãƒšãƒ¼ã‚¸æ•°: {page_count} ãƒšãƒ¼ã‚¸")
                st.info("ğŸ”„ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯1ãƒšãƒ¼ã‚¸ãšã¤å‡¦ç†ã•ã‚Œã¾ã™")
        except Exception as e:
            st.warning(f"PDFã®æƒ…å ±å–å¾—ã«å¤±æ•—: {str(e)}")
        
        # PDFã®è¡¨ç¤º
        with st.expander("PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
            pdf_display = f'<iframe src="data:application/pdf;base64,{uploaded_pdf.getvalue().hex()}" width="100%" height="500" type="application/pdf"></iframe>'
            st.markdown(pdf_display, unsafe_allow_html=True)
    
    # å‡¦ç†ãƒœã‚¿ãƒ³
    process_button = st.button(
        "ãƒšãƒ¼ã‚¸å˜ä½ã§å‡¦ç†é–‹å§‹",
        disabled=not (uploaded_pdf and api_key and model_name),
        help="ç‰¹è¨±PDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤å‡¦ç†ã—ã¦æ§‹é€ åŒ–JSONã‚’ç”Ÿæˆã—ã¾ã™"
    )

with col2:
    st.header("ğŸ“¥ å‡ºåŠ›")
    
    # PDFã‚’å‡¦ç†
    if process_button and uploaded_pdf and api_key and model_name:
        with st.status("ãƒšãƒ¼ã‚¸å˜ä½ã§å‡¦ç†ä¸­...", expanded=True) as status:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            pdf_path = save_upload_file(uploaded_pdf)
            
            if pdf_path:
                # é€²æ—è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
                progress_container = st.container()
                
                # ãƒšãƒ¼ã‚¸å˜ä½ã§å‡¦ç†
                result = process_pdf_by_pages(
                    pdf_path=pdf_path,
                    model_name=model_name,
                    api_key=api_key,
                    schema=schema,
                    prompt=custom_prompt if custom_prompt else None,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    progress_container=progress_container
                )
                
                # å‡¦ç†å®Œäº†
                if "error" in result:
                    status.update(label=f"ã‚¨ãƒ©ãƒ¼: {result['error']}", state="error")
                else:
                    status.update(label="å…¨ãƒšãƒ¼ã‚¸ã®å‡¦ç†å®Œäº†ï¼", state="complete")
                    
                    # å‡¦ç†çµæœã®çµ±è¨ˆæƒ…å ±
                    processing_summary = result.get("processing_summary", {})
                    total_pages = processing_summary.get("total_pages", 0)
                    successful_pages = processing_summary.get("successful_pages", 0)
                    failed_pages = processing_summary.get("failed_pages", 0)
                    
                    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    st.markdown("### å‡¦ç†çµæœæ¦‚è¦")
                    col_stats1, col_stats2, col_stats3 = st.columns(3)
                    with col_stats1:
                        st.markdown(f'<div class="stat-box blue-stat"><h3>{total_pages}</h3>ç·ãƒšãƒ¼ã‚¸æ•°</div>', unsafe_allow_html=True)
                    with col_stats2:
                        st.markdown(f'<div class="stat-box green-stat"><h3>{successful_pages}</h3>æˆåŠŸãƒšãƒ¼ã‚¸</div>', unsafe_allow_html=True)
                    with col_stats3:
                        st.markdown(f'<div class="stat-box orange-stat"><h3>{failed_pages}</h3>å¤±æ•—ãƒšãƒ¼ã‚¸</div>', unsafe_allow_html=True)
                    
                    # å‡¦ç†è©³ç´°ã®è¡¨ç¤º
                    if processing_summary.get("page_details"):
                        with st.expander("ãƒšãƒ¼ã‚¸åˆ¥å‡¦ç†è©³ç´°", expanded=False):
                            for detail in processing_summary["page_details"]:
                                if detail["status"] == "success":
                                    st.success(f"ãƒšãƒ¼ã‚¸ {detail['page_number']}: å‡¦ç†æˆåŠŸ")
                                else:
                                    st.error(f"ãƒšãƒ¼ã‚¸ {detail['page_number']}: {detail.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                    
                    # çµ±åˆã•ã‚ŒãŸæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ¼æ•°
                    data_keys = [k for k in result.keys() if k != "processing_summary"]
                    sections_count = sum(1 for k in data_keys if isinstance(result[k], dict))
                    
                    st.markdown("### æŠ½å‡ºãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
                    col_data1, col_data2 = st.columns(2)
                    with col_data1:
                        st.markdown(f'<div class="stat-box blue-stat"><h3>{len(data_keys)}</h3>ãƒ‡ãƒ¼ã‚¿è¦ç´ </div>', unsafe_allow_html=True)
                    with col_data2:
                        st.markdown(f'<div class="stat-box green-stat"><h3>{sections_count}</h3>ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°</div>', unsafe_allow_html=True)
                    
                    # çµ±åˆçµæœã®è¡¨ç¤ºï¼ˆprocessing_summaryã‚’é™¤ãï¼‰
                    display_result = {k: v for k, v in result.items() if k != "processing_summary"}
                    
                    # JSONçµæœã®è¡¨ç¤º
                    st.markdown("### çµ±åˆJSONå‡ºåŠ›")
                    st.json(display_result)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    json_str = json.dumps(result, ensure_ascii=False, indent=2)
                    output_filename = f"{Path(uploaded_pdf.name).stem}_merged.json"
                    
                    col_download1, col_download2 = st.columns(2)
                    with col_download1:
                        st.download_button(
                            label="ğŸ“¥ çµ±åˆJSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=json_str.encode("utf-8"),
                            file_name=output_filename,
                            mime="application/json",
                            help="ãƒšãƒ¼ã‚¸åˆ¥å‡¦ç†çµæœã‚’çµ±åˆã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™"
                        )
                    
                    with col_download2:
                        # ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆå‡¦ç†æƒ…å ±ã‚’é™¤ãï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        clean_json_str = json.dumps(display_result, ensure_ascii=False, indent=2)
                        clean_filename = f"{Path(uploaded_pdf.name).stem}_data_only.json"
                        st.download_button(
                            label="ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=clean_json_str.encode("utf-8"),
                            file_name=clean_filename,
                            mime="application/json",
                            help="å‡¦ç†æƒ…å ±ã‚’é™¤ã„ãŸæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™"
                        )
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                try:
                    os.remove(pdf_path)
                except:
                    pass
    else:
        # å‡¦ç†å‰ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        st.info("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Œãƒšãƒ¼ã‚¸å˜ä½ã§å‡¦ç†é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ã“ã“ã«çµ±åˆã•ã‚ŒãŸæ§‹é€ åŒ–JSONãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        
        # ãƒ‡ãƒ¢è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        with st.expander("å‡ºåŠ›ä¾‹"):
            example_output = {
                "processing_summary": {
                    "total_pages": 10,
                    "successful_pages": 9,
                    "failed_pages": 1,
                    "page_details": [
                        {"page_number": 1, "status": "success"},
                        {"page_number": 2, "status": "success"},
                        {"page_number": 3, "status": "error", "error": "ç”»åƒãŒä¸é®®æ˜"},
                        {"page_number": 4, "status": "success"}
                    ]
                },
                "publicationIdentifier": "WO2020123456A1",
                "FrontPage": {
                    "title": "AIé§†å‹•ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ",
                    "PublicationData": {
                        "PublicationNumber": "WO2020123456A1",
                        "PublicationDate": "2020-06-15",
                        "PublicationKind": "A1"
                    },
                    "Applicants": {"Applicant": [{"Name": "ã‚µãƒ³ãƒ—ãƒ«æ ªå¼ä¼šç¤¾"}]},
                    "Inventors": {"Inventor": [{"Name": "ç™ºæ˜ å¤ªéƒ"}]},
                    "Abstract": {"Paragraph": [{"content": "ã“ã‚Œã¯ç‰¹è¨±ã®è¦ç´„ã‚µãƒ³ãƒ—ãƒ«ã§ã™..."}]}
                },
                "Claims": {
                    "Claim": [
                        {"id": "claim1", "number": 1, "Text": {"content": "AIã‚’ä½¿ç”¨ã—ã¦ç‰¹è¨±æ–‡æ›¸ã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹æ–¹æ³•..."}},
                        {"id": "claim2", "number": 2, "Text": {"content": "è«‹æ±‚é …1ã«è¨˜è¼‰ã®æ–¹æ³•ã«ãŠã„ã¦..."}}
                    ]
                },
                "Description": {
                    "TechnicalField": {"Paragraph": [{"content": "æœ¬ç™ºæ˜ã¯ã€ç‰¹è¨±æ–‡æ›¸å‡¦ç†ã®åˆ†é‡ã«é–¢ã™ã‚‹..."}]},
                    "BackgroundArt": {"Paragraph": [{"content": "å¾“æ¥ã®ç‰¹è¨±æ–‡æ›¸å‡¦ç†ã§ã¯..."}]},
                    "SummaryOfInvention": {"Paragraph": [{"content": "æœ¬ç™ºæ˜ã®ç›®çš„ã¯..."}]}
                }
            }
            st.json(example_output)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")

# å‡¦ç†æ–¹æ³•ã®èª¬æ˜
with st.expander("ğŸ“– ãƒšãƒ¼ã‚¸å˜ä½å‡¦ç†ã«ã¤ã„ã¦", expanded=False):
    st.markdown("""
    ### ğŸ”„ ãƒšãƒ¼ã‚¸å˜ä½å‡¦ç†ã®ç‰¹å¾´
    
    **å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
    1. **PDFåˆ†å‰²**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‚’1ãƒšãƒ¼ã‚¸ãšã¤åˆ†å‰²ï¼ˆpypdfãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰
    2. **å€‹åˆ¥å‡¦ç†**: å„ãƒšãƒ¼ã‚¸ã‚’ç‹¬ç«‹ã—ã¦AIãƒ¢ãƒ‡ãƒ«ã§è§£æ
    3. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—**: å„ãƒšãƒ¼ã‚¸ã®å‡¦ç†çŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º
    4. **çµæœçµ±åˆ**: å…¨ãƒšãƒ¼ã‚¸ã®å‡¦ç†çµæœã‚’çµ±åˆã—ã¦ã²ã¨ã¤ã®JSONã‚’ç”Ÿæˆ
    5. **ã‚¨ãƒ©ãƒ¼è€æ€§**: ä¸€éƒ¨ã®ãƒšãƒ¼ã‚¸ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã®ãƒšãƒ¼ã‚¸ã®å‡¦ç†ã‚’ç¶™ç¶š
    
    **åˆ©ç‚¹:**
    - ğŸ“Š **é€²æ—ã®å¯è¦–åŒ–**: ã©ã®ãƒšãƒ¼ã‚¸ã¾ã§å‡¦ç†ãŒå®Œäº†ã—ãŸã‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¢ºèª
    - ğŸ›¡ï¸ **ã‚¨ãƒ©ãƒ¼è€æ€§**: ä¸€éƒ¨ãƒšãƒ¼ã‚¸ã®å¤±æ•—ãŒå…¨ä½“ã«å½±éŸ¿ã—ãªã„
    - ğŸ”§ **æŸ”è»Ÿãªçµ±åˆ**: è¤‡æ•°ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«çµåˆ
    - ğŸ’¾ **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: å¤§ããªPDFã‚‚åŠ¹ç‡çš„ã«å‡¦ç†
    
    **çµ±åˆãƒ«ãƒ¼ãƒ«:**
    - ğŸ“ **åŸºæœ¬æƒ…å ±**: æœ€åˆã«è¦‹ã¤ã‹ã£ãŸå€¤ã‚’ä½¿ç”¨ï¼ˆå…¬é–‹ç•ªå·ç­‰ï¼‰
    - ğŸ“š **é…åˆ—ãƒ‡ãƒ¼ã‚¿**: å…¨ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆè«‹æ±‚é …ã€æ®µè½ç­‰ï¼‰
    - ğŸ—ï¸ **æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿**: è¾æ›¸ã¯å†å¸°çš„ã«ãƒãƒ¼ã‚¸
    - âš ï¸ **ã‚¨ãƒ©ãƒ¼æƒ…å ±**: å‡¦ç†æ¦‚è¦ã«å¤±æ•—ãƒšãƒ¼ã‚¸ã®è©³ç´°ã‚’è¨˜éŒ²
    """)

st.markdown("""
<div style="text-align: center; color: #666;">
    ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ« - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”ŸæˆAIã‚’ä½¿ç”¨ã—ãŸç‰¹è¨±æ–‡æ›¸ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡º<br>
    <small>Powered by patent-extractor library Copyright (c) 2025 Pyxist Co.,Ltd</small><br>
    <small>ğŸ”„ ãƒšãƒ¼ã‚¸å˜ä½å‡¦ç†æ©Ÿèƒ½æ­è¼‰ - pypdf (MIT License) ã‚’ä½¿ç”¨ã—ãŸå®‰å®šã—ãŸPDFå‡¦ç†</small>
</div>
""", unsafe_allow_html=True)