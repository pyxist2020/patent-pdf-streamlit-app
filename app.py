import streamlit as st
import json
import os
import tempfile
import time
from pathlib import Path

from patent_extractor import StreamingPatentExtractor

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
    }
    .stButton button {
        width: 100%;
    }
    .stat-box {
        padding: 15px;
        border-radius: 8px;
        margin-bottom: 10px;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .blue-stat {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border: 1px solid #2196f3;
    }
    .green-stat {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border: 1px solid #4caf50;
    }
    .orange-stat {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc02 100%);
        border: 1px solid #ff9800;
    }
    .title-area {
        text-align: center;
        margin-bottom: 2rem;
    }
    .processing-indicator {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 10px;
        background-color: #e3f2fd;
        border-radius: 8px;
        margin: 10px 0;
    }
    .chat-container {
        height: 400px;
        overflow-y: auto;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 10px;
        background-color: #fafafa;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
DEFAULT_MODEL_OPTIONS = {
    "Google Gemini": ["gemini-1.5-pro", "gemini-1.5-flash"],
    "OpenAI": ["gpt-4o", "gpt-4-vision-preview"],
    "Anthropic": ["claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'is_processing' not in st.session_state:
        st.session_state.is_processing = False
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    if 'final_result' not in st.session_state:
        st.session_state.final_result = None
    if 'start_time' not in st.session_state:
        st.session_state.start_time = None
    if 'chunk_count' not in st.session_state:
        st.session_state.chunk_count = 0

init_session_state()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
def get_api_key_from_env(provider):
    """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—"""
    if provider == "Google Gemini":
        return os.environ.get("GOOGLE_API_KEY", "")
    elif provider == "OpenAI":
        return os.environ.get("OPENAI_API_KEY", "")
    elif provider == "Anthropic":
        return os.environ.get("ANTHROPIC_API_KEY", "")
    return ""

# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æ¨å®š
def get_model_prefix(provider):
    """ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
    if provider == "Google Gemini":
        return "gemini-"
    elif provider == "OpenAI":
        return "gpt-"
    elif provider == "Anthropic":
        return "claude-"
    return ""

# ãƒ¢ãƒ‡ãƒ«åãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
def is_valid_model_name(model_name, provider):
    """ãƒ¢ãƒ‡ãƒ«åã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not model_name:
        return False
    
    model_lower = model_name.lower()
    if provider == "Google Gemini":
        return "gemini" in model_lower
    elif provider == "OpenAI":
        return "gpt" in model_lower or "openai" in model_lower
    elif provider == "Anthropic":
        return "claude" in model_lower
    
    return True

# APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
@st.cache_data(ttl=3600)
def fetch_available_models(provider, api_key):
    """APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        if not api_key:
            return []
        
        if provider == "Google Gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models = genai.list_models()
            return [model.name.replace('models/', '') for model in models 
                   if 'generateContent' in model.supported_generation_methods]
        
        elif provider == "OpenAI":
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            model_names = [model.id for model in models.data 
                          if 'gpt' in model.id.lower() or 'vision' in model.id.lower()]
            return sorted(model_names, reverse=True)
        
        elif provider == "Anthropic":
            return [
                "claude-3-5-sonnet-20241022",
                "claude-3-opus-20240229",
                "claude-3-sonnet-20240229", 
                "claude-3-haiku-20240307",
                "claude-3-5-haiku-20241022"
            ]
        
        return []
        
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_models_with_cache(provider, api_key):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    if not api_key:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])
    
    try:
        available_models = fetch_available_models(provider, api_key)
        return available_models if available_models else DEFAULT_MODEL_OPTIONS.get(provider, [])
    except:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])

# JSONã‚¹ã‚­ãƒ¼ãƒã‚’ãƒ­ãƒ¼ãƒ‰
def load_schema(file_path=None, file_content=None):
    """JSONã‚¹ã‚­ãƒ¼ãƒã‚’ãƒ­ãƒ¼ãƒ‰"""
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        elif file_content:
            return json.loads(file_content)
        return {}
    except Exception as e:
        st.error(f"JSONã‚¹ã‚­ãƒ¼ãƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

# PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
def save_upload_file(uploaded_file):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getbuffer())
            return tmp.name
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
def reset_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    st.session_state.messages = []
    st.session_state.is_processing = False
    st.session_state.processing_complete = False
    st.session_state.final_result = None
    st.session_state.start_time = None
    st.session_state.chunk_count = 0

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.markdown('<div class="title-area">', unsafe_allow_html=True)
st.title("ğŸ§© ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰")
st.markdown("""
ç‰¹è¨±PDFã‹ã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”ŸæˆAIã‚’ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–JSONã‚’**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**ã§æŠ½å‡ºã—ã¾ã™ã€‚
Streamlitã®ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœã§AIã®å‡¦ç†éç¨‹ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
""")
st.markdown('</div>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
    provider = st.selectbox(
        "AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆGoogle Geminiã‚’æ¨å¥¨ï¼‰",
        options=list(DEFAULT_MODEL_OPTIONS.keys())
    )
    
    # APIã‚­ãƒ¼å…¥åŠ›
    api_key = st.text_input(
        f"{provider} APIã‚­ãƒ¼",
        value=get_api_key_from_env(provider),
        type="password",
        help="APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_input_type = st.radio(
        "ãƒ¢ãƒ‡ãƒ«é¸æŠæ–¹æ³•",
        options=["åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ", "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›"],
        horizontal=True
    )
    
    if model_input_type == "åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ":
        with st.spinner("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ä¸­..."):
            available_models = get_models_with_cache(provider, api_key)
        
        if available_models:
            if api_key:
                st.info(f"âœ… {len(available_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—")
            else:
                st.info("â„¹ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
            
            model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«", options=available_models)
            
            if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§æ›´æ–°"):
                st.cache_data.clear()
                st.rerun()
        else:
            st.error("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            model_name = ""
    else:
        model_placeholder = get_model_prefix(provider) + "model-name"
        model_name = st.text_input(
            "ãƒ¢ãƒ‡ãƒ«å",
            placeholder=model_placeholder,
            help=f"{provider}ã®ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›"
        )
        
        if model_name and not is_valid_model_name(model_name, provider):
            st.warning(f"âš ï¸ {model_name}ã¯{provider}ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    
    if model_name:
        st.success(f"é¸æŠãƒ¢ãƒ‡ãƒ«: **{model_name}**")
    
    # ã‚¹ã‚­ãƒ¼ãƒè¨­å®š
    schema_type = st.radio(
        "JSONã‚¹ã‚­ãƒ¼ãƒ",
        options=["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", "ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«", "ç›´æ¥å…¥åŠ›"],
        index=0
    )
    
    schema = {}
    if schema_type == "ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«":
        uploaded_schema = st.file_uploader("JSONã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«", type=["json"])
        if uploaded_schema:
            schema_content = uploaded_schema.getvalue().decode("utf-8")
            schema = load_schema(file_content=schema_content)
            if schema:
                st.success("ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿å®Œäº†")
    
    elif schema_type == "ç›´æ¥å…¥åŠ›":
        schema_text = st.text_area("JSONã‚¹ã‚­ãƒ¼ãƒã‚’å…¥åŠ›", height=200)
        if schema_text:
            try:
                schema = json.loads(schema_text)
                st.success("ã‚¹ã‚­ãƒ¼ãƒå½¢å¼OK")
            except json.JSONDecodeError:
                st.error("JSONå½¢å¼ã‚¨ãƒ©ãƒ¼")
    
    else:
        default_schema_path = "default_schema.json"
        if os.path.exists(default_schema_path):
            schema = load_schema(file_path=default_schema_path)
            st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒä½¿ç”¨")
        else:
            st.info("ç©ºã®ã‚¹ã‚­ãƒ¼ãƒã‚’ä½¿ç”¨")
    
    # è©³ç´°è¨­å®š
    with st.expander("è©³ç´°è¨­å®š"):
        custom_prompt = st.text_area("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", height=100)
        temperature = st.slider("Temperature", 0.0, 1.0, 0.1, 0.05)
        max_tokens = st.number_input("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 1024, 65535, 32768, 1024)
    
    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
        reset_session_state()
        st.rerun()

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¤ å…¥åŠ›")
    
    uploaded_pdf = st.file_uploader(
        "ç‰¹è¨±PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["pdf"],
        help="å‡¦ç†ã™ã‚‹ç‰¹è¨±PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
    )
    
    if uploaded_pdf:
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_pdf.name}")
        
        with st.expander("PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
            try:
                import base64
                pdf_base64 = base64.b64encode(uploaded_pdf.getvalue()).decode('utf-8')
                pdf_display = f'<iframe src="data:application/pdf;base64,{pdf_base64}" width="100%" height="500"></iframe>'
                st.markdown(pdf_display, unsafe_allow_html=True)
            except:
                st.info("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºä¸å¯")
    
    # å‡¦ç†ãƒœã‚¿ãƒ³
    process_disabled = not (uploaded_pdf and api_key and model_name) or st.session_state.is_processing
    
    if st.button(
        "ğŸš€ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†é–‹å§‹",
        disabled=process_disabled,
        help="ç‰¹è¨±PDFã‚’Streamlitãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†"
    ):
        if uploaded_pdf and api_key and model_name:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            reset_session_state()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            st.session_state.messages.append({
                "role": "user", 
                "content": f"ç‰¹è¨±PDFã€Œ{uploaded_pdf.name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„"
            })
            
            # å‡¦ç†çŠ¶æ…‹ã‚’é–‹å§‹ã«è¨­å®š
            st.session_state.is_processing = True
            st.session_state.start_time = time.time()
            
            st.rerun()

with col2:
    st.header("ğŸ“¥ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›")
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    if st.session_state.is_processing or st.session_state.processing_complete:
        col_stats1, col_stats2, col_stats3 = st.columns(3)
        
        with col_stats1:
            elapsed_time = (time.time() - st.session_state.start_time) if st.session_state.start_time else 0
            st.markdown(f'<div class="stat-box blue-stat"><h4>{elapsed_time:.1f}s</h4>çµŒéæ™‚é–“</div>', 
                       unsafe_allow_html=True)
        
        with col_stats2:
            st.markdown(f'<div class="stat-box green-stat"><h4>{st.session_state.chunk_count}</h4>å—ä¿¡ãƒãƒ£ãƒ³ã‚¯</div>', 
                       unsafe_allow_html=True)
        
        with col_stats3:
            status_text = "å®Œäº†" if st.session_state.processing_complete else "å‡¦ç†ä¸­"
            status_color = "green-stat" if st.session_state.processing_complete else "orange-stat"
            st.markdown(f'<div class="stat-box {status_color}"><h4>{status_text}</h4>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹</div>', 
                       unsafe_allow_html=True)
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
    if st.session_state.is_processing and uploaded_pdf:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦PDFã‚’ä¿å­˜
        pdf_path = save_upload_file(uploaded_pdf)
        
        if pdf_path:
            try:
                # ã‚¨ã‚¯ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã®åˆæœŸåŒ–
                extractor = StreamingPatentExtractor(
                    model_name=model_name,
                    api_key=api_key,
                    json_schema=schema,
                    user_prompt=custom_prompt if custom_prompt else None,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›
                with st.chat_message("assistant"):
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
                    response = st.write_stream(extractor.stream_patent_extraction(pdf_path))
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response
                })
                
                # JSONè§£æã¨æœ€çµ‚çµæœã®è¨­å®š
                try:
                    final_result = extractor._extract_json_from_text(response)
                    st.session_state.final_result = final_result
                except Exception as e:
                    st.session_state.final_result = {
                        "error": f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}", 
                        "raw_output": response
                    }
                
                # å‡¦ç†å®Œäº†
                st.session_state.is_processing = False
                st.session_state.processing_complete = True
                
                st.rerun()
                
            except Exception as e:
                st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.session_state.is_processing = False
                
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                try:
                    os.remove(pdf_path)
                except:
                    pass
    
    # æœ€çµ‚çµæœã®è¡¨ç¤ºã¨å‡¦ç†
    if st.session_state.processing_complete and st.session_state.final_result:
        st.markdown("---")
        st.markdown("### ğŸ“‹ æ§‹é€ åŒ–JSONçµæœ")
        
        # ã‚¨ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ã¿JSONã‚’è¡¨ç¤º
        if "error" not in st.session_state.final_result:
            st.json(st.session_state.final_result)
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if uploaded_pdf:
                json_str = json.dumps(st.session_state.final_result, ensure_ascii=False, indent=2)
                output_filename = f"{Path(uploaded_pdf.name).stem}_streaming.json"
                
                st.download_button(
                    label="ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=json_str.encode("utf-8"),
                    file_name=output_filename,
                    mime="application/json",
                    help="æŠ½å‡ºã•ã‚ŒãŸæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                )
                
                # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                json_size = len(json_str)
                keys_count = len(st.session_state.final_result.keys())
                
                col_result1, col_result2 = st.columns(2)
                with col_result1:
                    st.metric("JSONæ–‡å­—æ•°", f"{json_size:,}")
                with col_result2:
                    st.metric("ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«è¦ç´ ", keys_count)
        else:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
            st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {st.session_state.final_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            if "raw_output" in st.session_state.final_result:
                with st.expander("ç”Ÿå‡ºåŠ›ã‚’è¡¨ç¤º"):
                    st.text(st.session_state.final_result["raw_output"])
    
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆå‡¦ç†å‰ï¼‰
    if not st.session_state.is_processing and not st.session_state.processing_complete and not st.session_state.messages:
        st.info("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
        
        with st.expander("ğŸ’¡ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½ã«ã¤ã„ã¦"):
            st.markdown("""
            **ğŸš€ Streamlitãƒãƒ£ãƒƒãƒˆå½¢å¼ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ç‰¹å¾´:**
            
            - **âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º**: AIãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœã§è¡¨ç¤º
            - **ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå½¢å¼**: ä¼šè©±å½¢å¼ã§å‡¦ç†éç¨‹ã‚’ç¢ºèª
            - **ğŸ“Š é€²æ—è¿½è·¡**: çµŒéæ™‚é–“ã¨ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
            - **ğŸ¯ å³åº§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: å‡¦ç†é–‹å§‹ç›´å¾Œã‹ã‚‰çµæœãŒè¦‹ãˆã‚‹
            - **ğŸ“± ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–**: ãƒ¢ãƒã‚¤ãƒ«ã§ã‚‚å¿«é©ã«åˆ©ç”¨å¯èƒ½
            
            **ğŸ“‹ å¯¾å¿œæ©Ÿèƒ½:**
            - PDFç‰¹è¨±æ–‡æ›¸ã®æ§‹é€ åŒ–æŠ½å‡º
            - å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªãƒ»è‹±èªãªã©ï¼‰
            - å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ
            - JSONã‚¹ã‚­ãƒ¼ãƒã«ã‚ˆã‚‹ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
            - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
            **ğŸ”§ æŠ€è¡“çš„ç‰¹å¾´:**
            - `st.write_stream()` ã«ã‚ˆã‚‹ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå‡¦ç†
            - å®‰å®šã—ãŸã‚¨ãƒ©ãƒ¼å‡¦ç†
            """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«ï¼ˆStreamlitãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰ v3.0<br>
    <small>Powered by StreamingPatentExtractor with Streamlit Chat API | Copyright (c) 2025 Pyxist Co.,Ltd</small>
</div>
""", unsafe_allow_html=True)
        