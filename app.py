import streamlit as st
import json
import os
import tempfile
import time
from pathlib import Path

from patent_extractor import PatentExtractor

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«",
    page_icon="âš¡",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .metric-row {
        display: flex;
        gap: 20px;
        margin: 20px 0;
    }
    .metric-card {
        flex: 1;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
        border: 1px solid #e0e0e0;
    }
    .performance-info {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
DEFAULT_MODEL_OPTIONS = {
    "Google Gemini": ["gemini-1.5-pro", "gemini-1.5-flash"],
    "OpenAI": ["gpt-4o", "gpt-4-vision-preview"],
    "Anthropic": ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229"]
}

def get_api_key_from_env(provider):
    env_vars = {
        "Google Gemini": "GOOGLE_API_KEY",
        "OpenAI": "OPENAI_API_KEY", 
        "Anthropic": "ANTHROPIC_API_KEY"
    }
    return os.environ.get(env_vars.get(provider, ""), "")

@st.cache_data(ttl=3600)
def fetch_available_models(provider, api_key):
    """APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        if not api_key:
            return []
        
        if provider == "Google Gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models = genai.list_models()
            return [model.name.replace('models/', '') for model in models 
                   if 'generateContent' in model.supported_generation_methods]
        
        elif provider == "OpenAI":
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            model_names = [model.id for model in models.data 
                          if 'gpt' in model.id.lower() or 'vision' in model.id.lower()]
            return sorted(model_names, reverse=True)
        
        elif provider == "Anthropic":
            # Anthropicã®APIã¯ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æä¾›ã—ã¦ã„ãªã„ãŸã‚ã€æ—¢çŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
            return [
                "claude-3-5-sonnet-20241022",
                "claude-3-5-haiku-20241022",
                "claude-3-opus-20240229",
                "claude-3-sonnet-20240229", 
                "claude-3-haiku-20240307"
            ]
        
        return []
        
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return []

def get_models_with_cache(provider, api_key):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    if not api_key:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])
    
    try:
        available_models = fetch_available_models(provider, api_key)
        if available_models:
            return available_models
        else:
            return DEFAULT_MODEL_OPTIONS.get(provider, [])
    except:
        return DEFAULT_MODEL_OPTIONS.get(provider, [])

def load_schema(file_path=None, file_content=None):
    try:
        if file_path and os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        elif file_content:
            return json.loads(file_content)
        return {}
    except Exception as e:
        st.error(f"ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

def process_pdf(pdf_path, model_name, api_key, schema, prompt=None, temperature=0.1, max_tokens=4096, max_workers=8):
    try:
        extractor = PatentExtractor(
            model_name=model_name,
            api_key=api_key,
            json_schema=schema,
            user_prompt=prompt,
            temperature=temperature,
            max_tokens=max_tokens,
            max_workers=max_workers
        )
        return extractor.process_patent_pdf(pdf_path)
    except Exception as e:
        return {"error": str(e)}

def save_upload_file(uploaded_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getbuffer())
            return tmp.name
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def display_performance_metrics(processing_info):
    if not processing_info:
        return
    
    total_time = processing_info.get("total_time_seconds", 0)
    field_timing = processing_info.get("field_timing", {})
    workers = processing_info.get("parallel_workers", 1)
    
    st.markdown("### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·å‡¦ç†æ™‚é–“", f"{total_time:.1f}ç§’")
    with col2:
        st.metric("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼", f"{workers}")
    with col3:
        st.metric("å‡¦ç†ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰", f"{len(field_timing)}")
    with col4:
        estimated_sequential = sum(field_timing.values()) if field_timing else total_time
        speedup = estimated_sequential / total_time if total_time > 0 else 1
        st.metric("é«˜é€ŸåŒ–", f"{speedup:.1f}x")
    
    if field_timing:
        with st.expander("ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¥å‡¦ç†æ™‚é–“"):
            for field, timing in sorted(field_timing.items(), key=lambda x: x[1], reverse=True):
                st.write(f"**{field}**: {timing:.2f}ç§’")

# ãƒ¡ã‚¤ãƒ³UI
st.title("âš¡ ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ«")
st.markdown("ç‰¹è¨±PDFã‹ã‚‰æ§‹é€ åŒ–JSONã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸæŠ½å‡º")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("è¨­å®š")
    
    # ä¸¦åˆ—å‡¦ç†è¨­å®š
    max_workers = st.slider("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°", 1, 16, 8, help="åŒæ™‚å‡¦ç†æ•°")
    
    # AIãƒ¢ãƒ‡ãƒ«è¨­å®š
    provider = st.selectbox("AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", list(DEFAULT_MODEL_OPTIONS.keys()))
    api_key = st.text_input(f"{provider} APIã‚­ãƒ¼", value=get_api_key_from_env(provider), type="password")
    
    # ãƒ¢ãƒ‡ãƒ«å–å¾—ã¨é¸æŠ
    with st.spinner("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ä¸­..."):
        available_models = get_models_with_cache(provider, api_key)
    
    if available_models:
        if api_key:
            st.info(f"âœ… {len(available_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—")
        else:
            st.info("â„¹ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º")
        
        model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«", available_models)
        
        # ãƒ¢ãƒ‡ãƒ«æ›´æ–°ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’æ›´æ–°"):
            st.cache_data.clear()
            st.rerun()
    else:
        st.error("ãƒ¢ãƒ‡ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        model_name = ""
    
    # ã‚¹ã‚­ãƒ¼ãƒè¨­å®š
    schema_type = st.radio("JSONã‚¹ã‚­ãƒ¼ãƒ", ["ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ç›´æ¥å…¥åŠ›"])
    
    schema = {}
    if schema_type == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        uploaded_schema = st.file_uploader("ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«", type=["json"])
        if uploaded_schema:
            schema = load_schema(file_content=uploaded_schema.getvalue().decode("utf-8"))
            if schema:
                st.success("ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿å®Œäº†")
    elif schema_type == "ç›´æ¥å…¥åŠ›":
        schema_text = st.text_area("JSONã‚¹ã‚­ãƒ¼ãƒ", height=150)
        if schema_text:
            try:
                schema = json.loads(schema_text)
                st.success("ã‚¹ã‚­ãƒ¼ãƒå½¢å¼OK")
            except:
                st.error("JSONå½¢å¼ã‚¨ãƒ©ãƒ¼")
    else:
        if os.path.exists("default_schema.json"):
            schema = load_schema(file_path="default_schema.json")
            st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚­ãƒ¼ãƒä½¿ç”¨")
    
    # è©³ç´°è¨­å®š
    with st.expander("è©³ç´°è¨­å®š"):
        custom_prompt = st.text_area("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", height=80)
        temperature = st.slider("Temperature", 0.0, 1.0, 0.1, 0.05)
        max_tokens = st.number_input("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 1024, 32768, 4096, 1024)

# ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒªã‚¢
col1, col2 = st.columns([1, 1])

with col1:
    st.header("å…¥åŠ›")
    
    uploaded_pdf = st.file_uploader("ç‰¹è¨±PDFãƒ•ã‚¡ã‚¤ãƒ«", type=["pdf"])
    
    if uploaded_pdf:
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_pdf.name}")
    
    process_button = st.button(
        f"ä¸¦åˆ—å‡¦ç†é–‹å§‹ ({max_workers}workers)",
        disabled=not (uploaded_pdf and api_key and model_name),
        use_container_width=True
    )

with col2:
    st.header("å‡ºåŠ›")
    
    if process_button and uploaded_pdf and api_key and model_name:
        pdf_path = save_upload_file(uploaded_pdf)
        
        if pdf_path:
            with st.spinner(f"{model_name}ã§ä¸¦åˆ—å‡¦ç†ä¸­..."):
                start_time = time.time()
                result = process_pdf(
                    pdf_path=pdf_path,
                    model_name=model_name,
                    api_key=api_key,
                    schema=schema,
                    prompt=custom_prompt if custom_prompt else None,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    max_workers=max_workers
                )
                
                if "error" in result:
                    st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
                else:
                    st.success("å‡¦ç†å®Œäº†ï¼")
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±è¡¨ç¤º
                    if "_processing_info" in result:
                        display_performance_metrics(result["_processing_info"])
                    
                    # çµæœçµ±è¨ˆ
                    clean_result = {k: v for k, v in result.items() if not k.startswith('_')}
                    total_fields = len(clean_result)
                    successful_fields = len([v for v in clean_result.values() if not (isinstance(v, dict) and 'error' in v)])
                    
                    st.write(f"**æŠ½å‡ºçµæœ**: {successful_fields}/{total_fields} ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æˆåŠŸ")
                    
                    # JSONè¡¨ç¤º
                    st.json(clean_result)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    json_str = json.dumps(clean_result, indent=2, ensure_ascii=False)
                    output_filename = f"{Path(uploaded_pdf.name).stem}.json"
                    
                    st.download_button(
                        "JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=json_str.encode("utf-8"),
                        file_name=output_filename,
                        mime="application/json",
                        use_container_width=True
                    )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            try:
                os.remove(pdf_path)
            except:
                pass
    else:
        st.info("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        
        # ç°¡å˜ãªä¾‹
        with st.expander("å‡ºåŠ›ä¾‹"):
            example = {
                "publicationIdentifier": "WO2024123456A1",
                "FrontPage": {"title": "AIç‰¹è¨±æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ "},
                "Claims": {"Claim": [{"id": "1", "Text": {"content": "AIã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•..."}}]},
                "Description": {"TechnicalField": {"Paragraph": [{"content": "AIåˆ†é‡ã«é–¢ã™ã‚‹..."}]}}
            }
            st.json(example)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "ç‰¹è¨±PDFæ§‹é€ åŒ–ãƒ„ãƒ¼ãƒ« - ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿãƒ‡ãƒ¼ã‚¿æŠ½å‡º"
    "</div>", 
    unsafe_allow_html=True
)